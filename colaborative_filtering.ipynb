{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pglhz3pCwaeF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SII4lpVK0GI0"
      },
      "outputs": [],
      "source": [
        "search_history = pd.read_csv('expanded_search_history.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MgKM0cPX2qm1"
      },
      "outputs": [],
      "source": [
        "search_history['item_id'] = search_history['search'].astype('category').cat.codes\n",
        "search_history['user_id'] = search_history['user_id'].astype('category').cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZTqh0I693zMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4c024d-64e9-41e7-ca08-0ce970eaa01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max user_id: 6486, Max item_id: 19\n"
          ]
        }
      ],
      "source": [
        "user_ids = search_history['user_id'].values\n",
        "item_ids = search_history['item_id'].values\n",
        "\n",
        "print(f\"Max user_id: {user_ids.max()}, Max item_id: {item_ids.max()}\")\n",
        "\n",
        "train_data, test_data = train_test_split(search_history, test_size=0.2, random_state=30)\n",
        "\n",
        "train_user_ids = train_data['user_id'].values\n",
        "train_item_ids = train_data['item_id'].values\n",
        "\n",
        "test_user_ids = test_data['user_id'].values\n",
        "test_item_ids = test_data['item_id'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4J1tyrMDQ1x",
        "outputId": "31ac98c6-5521-4a09-9810-1e19c656008d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users: 6488, Number of items: 21\n",
            "user_id\n",
            "227     8\n",
            "5217    6\n",
            "1607    6\n",
            "3268    6\n",
            "903     6\n",
            "       ..\n",
            "2618    1\n",
            "6136    1\n",
            "896     1\n",
            "2125    1\n",
            "3303    1\n",
            "Name: count, Length: 5619, dtype: int64\n",
            "item_id\n",
            "16    471\n",
            "14    434\n",
            "17    429\n",
            "1     428\n",
            "5     422\n",
            "18    421\n",
            "19    420\n",
            "0     419\n",
            "8     412\n",
            "11    410\n",
            "4     407\n",
            "10    406\n",
            "12    403\n",
            "7     401\n",
            "3     400\n",
            "9     400\n",
            "2     394\n",
            "15    389\n",
            "13    387\n",
            "6     387\n",
            "Name: count, dtype: int64\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " user_input (InputLayer)     [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " item_input (InputLayer)     [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " user_embedding (Embedding)  (None, 1, 16)                103808    ['user_input[0][0]']          \n",
            "                                                                                                  \n",
            " item_embedding (Embedding)  (None, 1, 16)                336       ['item_input[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 16)                   0         ['user_embedding[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 16)                   0         ['item_embedding[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 32)                   0         ['flatten[0][0]',             \n",
            "                                                                     'flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 8)                    264       ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 8)                    32        ['dense[0][0]']               \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 8)                    0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 4)                    36        ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 4)                    16        ['dense_1[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 4)                    0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    5         ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 104497 (408.19 KB)\n",
            "Trainable params: 104473 (408.10 KB)\n",
            "Non-trainable params: 24 (96.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_users = search_history['user_id'].nunique() + 1\n",
        "num_items = search_history['item_id'].nunique() + 1\n",
        "print(f\"Number of users: {num_users}, Number of items: {num_items}\")\n",
        "\n",
        "print(train_data['user_id'].value_counts())\n",
        "print(train_data['item_id'].value_counts())\n",
        "\n",
        "input_users = tf.keras.layers.Input(shape=(1,), name='user_input')\n",
        "input_items = tf.keras.layers.Input(shape=(1,), name='item_input')\n",
        "\n",
        "embed_users = tf.keras.layers.Embedding(input_dim=num_users, output_dim=16, name='user_embedding')(input_users)\n",
        "embed_items = tf.keras.layers.Embedding(input_dim=num_items, output_dim=16, name='item_embedding')(input_items)\n",
        "\n",
        "flat_users = tf.keras.layers.Flatten()(embed_users)\n",
        "flat_items = tf.keras.layers.Flatten()(embed_items)\n",
        "\n",
        "concat = tf.keras.layers.Concatenate()([flat_users, flat_items])\n",
        "dense = tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(concat)\n",
        "dense = tf.keras.layers.BatchNormalization()(dense)\n",
        "dropout = tf.keras.layers.Dropout(0.5)(dense)\n",
        "dense = tf.keras.layers.Dense(4, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(dropout)\n",
        "dense = tf.keras.layers.BatchNormalization()(dense)\n",
        "dropout = tf.keras.layers.Dropout(0.5)(dense)\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid')(dropout)\n",
        "\n",
        "model = tf.keras.Model([input_users, input_items], output)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr0oawjQMqop",
        "outputId": "e9eff552-7854-4c1e-f645-c1c30af8a9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "258/258 [==============================] - 3s 5ms/step - loss: 0.8955 - accuracy: 0.5964 - val_loss: 0.6362 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.5012 - accuracy: 0.8996 - val_loss: 0.3754 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.3153 - accuracy: 0.9870 - val_loss: 0.2036 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.1970 - accuracy: 0.9942 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.1333 - accuracy: 0.9947 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "258/258 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9971 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "258/258 [==============================] - 1s 6ms/step - loss: 0.0659 - accuracy: 0.9981 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "258/258 [==============================] - 2s 6ms/step - loss: 0.0489 - accuracy: 0.9988 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "258/258 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(({'user_input': train_user_ids, 'item_input': train_item_ids}, np.ones(len(train_user_ids))))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(({'user_input': test_user_ids, 'item_input': test_item_ids}, np.ones(len(test_user_ids))))\n",
        "test_dataset = test_dataset.batch(32)\n",
        "\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=test_dataset)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}